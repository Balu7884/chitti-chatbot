{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procrastination is the habit of delaying or putting off tasks, decisions, or actions, often to the point where they become urgent or even impossible to complete. It's a common phenomenon where individuals intentionally or unintentionally avoid tasks that they find unpleasant, difficult, or overwhelming.\n",
      "\n",
      "Procrastination can take many forms, such as:\n",
      "\n",
      "1. **Task avoidance**: Putting off tasks that are due or need to be done, often until the last minute.\n",
      "2. **Decision delay**: Avoiding making decisions or putting them off until the last possible moment.\n",
      "3. **Time management**: Spending too much time on non-essential activities, such as social media, email, or watching TV, instead of focusing on important tasks.\n",
      "4. **Perfectionism**: Delaying tasks because of a fear of not doing them perfectly.\n",
      "\n",
      "Procrastination can be caused by various factors, including:\n",
      "\n",
      "1. **Fear of failure**: Fear of not meeting expectations or making mistakes.\n",
      "2. **Lack of motivation**: Feeling unenthusiastic or disconnected from the task.\n",
      "3. **Overwhelm**: Feeling overwhelmed by the task or its complexity.\n",
      "4. **Distractions**: Being easily distracted by social media, email, or other non-essential activities.\n",
      "5. **Avoidance**: Avoiding tasks that are unpleasant or uncomfortable.\n",
      "\n",
      "The consequences of procrastination can be severe, including:\n",
      "\n",
      "1. **Reduced productivity**: Putting off tasks can lead to missed deadlines, lost opportunities, and decreased productivity.\n",
      "2. **Increased stress**: Procrastination can lead to increased stress, anxiety, and feelings of guilt.\n",
      "3. **Poor performance**: Delaying tasks can result in poor performance, mistakes, and a lack of progress.\n",
      "4. **Missed opportunities**: Procrastination can lead to missed opportunities, such as promotions, new experiences, or personal growth.\n",
      "\n",
      "To overcome procrastination, it's essential to:\n",
      "\n",
      "1. **Identify the underlying causes**: Understand the reasons behind your procrastination.\n",
      "2. **Break tasks into smaller steps**: Divide large tasks into smaller, manageable steps.\n",
      "3. **Set clear goals and deadlines**: Establish specific goals and deadlines to help stay focused.\n",
      "4. **Create a schedule**: Plan out your day, week, or month to stay organized and on track.\n",
      "5. **Use productivity tools**: Utilize tools, such as to-do lists, calendars, or apps, to help stay organized and focused.\n",
      "6. **Seek support**: Share your struggles with a friend, family member, or mentor to gain support and accountability.\n",
      "\n",
      "Remember, overcoming procrastination takes time, effort, and practice. Be patient, kind, and compassionate with yourself as you work to develop new habits and strategies to achieve your goals.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "        temperature = 0,\n",
    "        groq_api_key = \"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\",\n",
    "        model_name = \"llama-3.1-8b-instant\"\n",
    "    )\n",
    "res = llm.invoke(\"What is procrasination\")\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader , DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from gtts import gTTS\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARSHITH\\AppData\\Local\\Temp\\ipykernel_27332\\50765638.py:14: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\VARSHITH\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARSHITH\\AppData\\Local\\Temp\\ipykernel_27332\\50765638.py:16: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vector_db.persist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB created and data saved\n",
      "Initializing Chatbot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VARSHITH\\AppData\\Local\\Temp\\ipykernel_27332\\50765638.py:48: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
      "C:\\Users\\VARSHITH\\AppData\\Local\\Temp\\ipykernel_27332\\50765638.py:56: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot :  Hello there, I'm so glad you reached out. It's completely normal to have ups and downs in life, and I'm here to listen and support you in any way I can. \n",
      "\n",
      "You mentioned something about mental health, and I'd like to start by acknowledging that everyone has their own unique interpretation of what a good life is. It's a very personal and subjective concept, and what brings happiness and fulfillment to one person may not be the same for another.\n",
      "\n",
      "Rowling et al. (2002) define mental health as the ability to live a life that is meaningful and fulfilling to the individual. It's about being able to navigate life's challenges with resilience, hope, and a sense of purpose.\n",
      "\n",
      "If you're feeling overwhelmed or struggling with your mental health, please know that you're not alone. I'm here to listen and offer support. What's been on your mind lately?\n",
      "Chatbot : I hope I was able to help you. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def initialize_llm():\n",
    "    llm = ChatGroq(\n",
    "        temperature = 0,\n",
    "        groq_api_key = \"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\",\n",
    "        model_name = \"llama-3.1-8b-instant\"\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "def create_vector_db():\n",
    "    loader = DirectoryLoader(\"Data\", glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vector_db = Chroma.from_documents(texts, embeddings, persist_directory='./chroma_db')\n",
    "    vector_db.persist()\n",
    "    print(\"ChromaDB created and data saved\")\n",
    "    return vector_db\n",
    "\n",
    "create_vector_db()\n",
    "\n",
    "def setup_qa_chain(vector_db ,llm):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    prompt_templates = ''' you are a compassionate mental health chatbot.Respond through\n",
    "    {context}\n",
    "    user : {question}\n",
    "    ChatBot :\n",
    "    '''\n",
    "    prompt = PromptTemplate(template = prompt_templates , input_variables = ['context','question'])\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm = llm,\n",
    "        chain_type = 'stuff',\n",
    "        retriever = retriever,\n",
    "        chain_type_kwargs = {\"prompt\" : prompt}\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "def main():\n",
    "    print(\"Initializing Chatbot\")\n",
    "    llm = initialize_llm()\n",
    "    db_path = './chroma_db'\n",
    "    \n",
    "    if not os.path.exists(db_path):\n",
    "        print(\"Creating ChromaDB\")\n",
    "        vector_db = create_vector_db()\n",
    "    else:\n",
    "        embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "        vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
    "    qa_chain = setup_qa_chain(vector_db, llm)\n",
    "\n",
    "    while True:\n",
    "        query = input(\"You : \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Chatbot : I hope I was able to help you. Goodbye!\")\n",
    "            break\n",
    "        response = qa_chain.run(query)\n",
    "        print(\"Chatbot : \", response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DirectoryLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChromaDB created and data saved\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vector_db\n\u001b[1;32m---> 20\u001b[0m create_vector_db()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup_qa_chain\u001b[39m(vector_db ,llm):\n\u001b[0;32m     23\u001b[0m     retriever \u001b[38;5;241m=\u001b[39m vector_db\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m, in \u001b[0;36mcreate_vector_db\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_vector_db\u001b[39m():\n\u001b[1;32m---> 10\u001b[0m     loader \u001b[38;5;241m=\u001b[39m DirectoryLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m, glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, loader_cls\u001b[38;5;241m=\u001b[39mPyPDFLoader)\n\u001b[0;32m     11\u001b[0m     documents \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m     12\u001b[0m     text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DirectoryLoader' is not defined"
     ]
    }
   ],
   "source": [
    "def initialize_llm():\n",
    "    llm = ChatGroq(\n",
    "        temperature = 0,\n",
    "        groq_api_key = \"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\",\n",
    "        model_name = \"llama-3.1-8b-instant\"\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "def create_vector_db():\n",
    "    loader = DirectoryLoader(\"Data\", glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vector_db = Chroma.from_documents(texts, embeddings, persist_directory='./chroma_db')\n",
    "    vector_db.persist()\n",
    "    print(\"ChromaDB created and data saved\")\n",
    "    return vector_db\n",
    "\n",
    "create_vector_db()\n",
    "\n",
    "def setup_qa_chain(vector_db ,llm):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    prompt_templates = ''' you are a compassionate mental health chatbot.Respond through\n",
    "    {context}\n",
    "    user : {question}\n",
    "    ChatBot :\n",
    "    '''\n",
    "    prompt = PromptTemplate(template = prompt_templates , input_variables = ['context','question'])\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm = llm,\n",
    "        chain_type = 'stuff',\n",
    "        retriever = retriever,\n",
    "        chain_type_kwargs = {\"prompt\" : prompt}\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "\n",
    "print(\"Initializing Chatbot\")\n",
    "llm = initialize_llm()\n",
    "db_path = './chroma_db'\n",
    "    \n",
    "if not os.path.exists(db_path):\n",
    "    print(\"Creating ChromaDB\")\n",
    "    vector_db = create_vector_db()\n",
    "else:\n",
    "    embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
    "qa_chain = setup_qa_chain(vector_db, llm)\n",
    "\n",
    "\n",
    "'''def chatbot(user_input, history=None):\n",
    "    if history is None:\n",
    "        history = []\n",
    "    \n",
    "    if not user_input.strip():\n",
    "        response = \"You can trust on me, don't be afraid or shy to share your thoughts.\"\n",
    "    else:\n",
    "        response = qa_chain.run(user_input)\n",
    "    \n",
    "    # Ensure response is a string\n",
    "    if isinstance(response, tuple):\n",
    "        response = response[0]  # Extract the first element if it's a tuple\n",
    "    \n",
    "    if not isinstance(response, str):\n",
    "        response = \"Sorry, I couldn't understand your request.\"\n",
    "    \n",
    "    # Convert text response to speech using gTTS\n",
    "    tts = gTTS(response, lang='en')\n",
    "    \n",
    "    # Save to a temporary file\n",
    "    with tempfile.NamedTemporaryFile(delete=True) as tmpfile:\n",
    "        tts.save(tmpfile.name)\n",
    "        audio_file = tmpfile.name\n",
    "    \n",
    "    # Append the response to the history\n",
    "    history.append({\"role\": \"assistant\", \"content\": response})\n",
    "    \n",
    "    # Return both the response text and the audio file path\n",
    "    return history, audio_file\n",
    "\n",
    "# Gradio interface\n",
    "with gr.Blocks() as app:\n",
    "    with gr.Column():\n",
    "        # Use gr.Chatbot for chat messages\n",
    "        chatbot_interface = gr.Chatbot()\n",
    "        \n",
    "        # Text input for user to send a message\n",
    "        user_input = gr.Textbox(placeholder=\"Type your message here...\", label=\"User Input\")\n",
    "        \n",
    "        # Output fields\n",
    "        audio_output = gr.Audio()\n",
    "\n",
    "    # Create a button to trigger chat submission\n",
    "    user_input.submit(chatbot, inputs=[user_input, chatbot_interface], outputs=[chatbot_interface, audio_output])\n",
    "\n",
    "app.launch()'''\n",
    "\n",
    "def chatbot(user_input, history=None):\n",
    "    if not user_input.strip():\n",
    "        return \"You can trust on me, don't be afraid or shy to share your thoughts.\"\n",
    "    \n",
    "    response = qa_chain.run(user_input)\n",
    "    \n",
    "    # Ensure response is a string\n",
    "    if isinstance(response, tuple):\n",
    "        response = response[0]  # Extract the first element if it's a tuple\n",
    "    \n",
    "    if not isinstance(response, str):\n",
    "        response = \"Sorry, I couldn't understand your request.\"\n",
    "    \n",
    "    # Return only the response\n",
    "    return response\n",
    "\n",
    "with gr.Blocks(theme='Respair/Shiki@1.2.1') as app:\n",
    "    chatbot_interface = gr.ChatInterface(fn=chatbot, title=\"Bujji : The Mentalist\", type='messages')\n",
    "\n",
    "app.launch(share=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
